# # Set global options
data_dir = "/var/lib/vector"

# # Vector's API (disabled by default)
# # Enable and try it out with the `vector top` command
# [api]
# enabled = true
# address = "0.0.0.0:8686"

[sources.my_source_id]
type = "internal_logs"

# # Structure and parse via Vector's Remap Language
# [transforms.apache_parser]
# inputs = ["apache_logs"]
# type   = "remap"
# source = '''
# . = parse_apache_log(.message)
# '''

# # Sample the data to save on cost
# [transforms.apache_sampler]
# inputs = ["apache_parser"]
# type   = "sampler"
# rate   = 50                   # only keep 50%

[sinks.elastic]
type = "elasticsearch"
inputs = [ "my_source_id" ]
endpoint = "http://elastic-hot:9200"
mode = "bulk"
# pipeline = "pipeline-name"
compression = "none"
# healthcheck = false

[sinks.elastic.bulk]
index = "vector-%Y-%m-%d"

# # Send structured data to a cost-effective long-term storage
# [sinks.s3_archives]
# inputs          = ["apache_parser"]    # don't sample for S3
# type            = "aws_s3"
# region          = "us-east-1"
# bucket          = "my-log-archives"
# key_prefix      = "date=%Y-%m-%d"      # daily partitions, hive friendly format
# compression     = "gzip"               # compress final objects
# encoding        = "ndjson"             # new line delimited JSON
# batch.max_bytes = 10000000             # 10mb uncompressed